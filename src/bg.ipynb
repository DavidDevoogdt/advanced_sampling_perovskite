{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "Kernel Python 3.8.2 is not usable. Check the Jupyter output tab for more information. \n",
      "View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first define system dimensionality and a target energy/distribution\n",
    "\n",
    "dim = 2\n",
    "\n",
    "# from .perovskite_energy import PerovskiteEnergy\n",
    "\n",
    "\n",
    "import code\n",
    "from code.perovskite_energy import PerovskiteEnergy\n",
    "from code.ASEbridge import ASEbridge\n",
    "\n",
    "\n",
    "\n",
    "# from  src.boltzmann_generators.perovskite_energy import PerovskiteEnergy\n",
    "\n",
    "\n",
    "\n",
    "target = PerovskiteEnergy(dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define some plotting functions\n",
    "\n",
    "from bgflow.utils.types import assert_numpy\n",
    "\n",
    "def plot_energy(energy, extent=(-2.5, 2.5), resolution=100, dim=2):\n",
    "    \"\"\" Plot energy functions in 2D \"\"\"\n",
    "    xs = torch.meshgrid([torch.linspace(*extent, resolution) for _ in range(2)])\n",
    "    xs = torch.stack(xs, dim=-1).view(-1, 2)\n",
    "    xs = torch.cat([\n",
    "        xs,\n",
    "        torch.Tensor(xs.shape[0], dim - xs.shape[-1]).zero_()\n",
    "    ], dim=-1)\n",
    "    us = energy.energy(xs).view(resolution, resolution)\n",
    "    us = torch.exp(-us)\n",
    "    plt.imshow(assert_numpy(us).T, extent=extent * 2)\n",
    "    plt.xlim=(extent[0], extent[1])\n",
    "    plt.ylim=(extent[0], extent[1])\n",
    "\n",
    "\n",
    "def plot_samples(samples, weights=None, range=None):\n",
    "    \"\"\" Plot sample histogram in 2D \"\"\"\n",
    "    samples = assert_numpy(samples)\n",
    "    plt.hist2d(\n",
    "        samples[:, 0], \n",
    "        -samples[:, 1],\n",
    "        weights=assert_numpy(weights) if weights is not None else weights,\n",
    "        bins=100,\n",
    "        norm=mpl.colors.LogNorm(),\n",
    "        range=range\n",
    "    )\n",
    "    \n",
    "def plot_bg(bg, target, n_samples=10000, range=[-2.5, 2.5], dim=2):\n",
    "    \"\"\" Plot target energy, bg energy and bg sample histogram\"\"\"\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plot_energy(target, extent=range, dim=dim)\n",
    "    plt.title(\"Target energy\")\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plot_energy(bg, extent=range, dim=dim)\n",
    "    plt.title(\"BG energy\")\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plot_samples(bg.sample(n_samples), range=[range, range])\n",
    "    plt.title(\"BG samples\")\n",
    "\n",
    "def plot_weighted_energy_estimate(bg, target, n_samples=100000, extent=None, n_bins=100, range=[-2, 2], dim=dim):\n",
    "    \"\"\" Plot weighed energy from samples \"\"\"\n",
    "    samples, latent, dlogp = bg.sample(n_samples, with_latent=True, with_dlogp=True)\n",
    "    log_weights = bg.log_weights_given_latent(samples, latent, dlogp)\n",
    "\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    \n",
    "    plt.subplot(1, 3, 1)\n",
    "    _, bins, _ = plt.hist(assert_numpy(samples[:, 0]), histtype=\"step\", log=True, bins=n_bins, weights=None, density=True, label=\"samples\", range=range)\n",
    "    xs = torch.linspace(*range, n_bins).view(-1, 1)\n",
    "    xs = torch.cat([xs, torch.zeros(xs.shape[0], dim - 1)], dim=-1).view(-1, dim)\n",
    "    us = target.energy(xs).view(-1)\n",
    "    us = torch.exp(-us)\n",
    "    us = us / torch.sum(us * (bins[-1] - bins[0]) / n_bins)\n",
    "    plt.plot(xs[:, 0], us, label=\"$\\log p(x)$\")\n",
    "    plt.xlabel(\"$x0$\")\n",
    "    plt.ylabel(\"log density\")\n",
    "    plt.legend()\n",
    "    plt.title(\"unweighed energy\")\n",
    "    \n",
    "    plt.subplot(1, 3, 2)\n",
    "    _, bins, _ = plt.hist(assert_numpy(samples[:, 0]), histtype=\"step\", log=True, bins=n_bins, weights=assert_numpy(log_weights.exp()), density=True, label=\"samples\", range=range)\n",
    "    plt.plot(xs[:, 0], us, label=\"$\\log p(x)$\")\n",
    "    plt.xlabel(\"$x0$\")\n",
    "    plt.legend()\n",
    "    plt.title(\"weighed energy\")\n",
    "\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.xlabel(\"$x0$\")\n",
    "    plt.ylabel(\"$x1$\")\n",
    "    plot_samples(samples, weights=log_weights.exp(), range=[range, range])\n",
    "    plt.title(\"weighed samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot target energy\n",
    "plot_energy(target, dim=dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a MCMC sampler to sample from the target energy\n",
    "\n",
    "from bgflow import GaussianMCMCSampler\n",
    "\n",
    "init_state = torch.Tensor([[-2, 0], [2, 0]])\n",
    "init_state = torch.cat([init_state, torch.Tensor(init_state.shape[0], dim-2).normal_()], dim=-1)\n",
    "target_sampler = GaussianMCMCSampler(target, init_state=init_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample some data \n",
    "\n",
    "data = target_sampler.sample(50000)\n",
    "\n",
    "plot_samples(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.pow(2).sum(dim=-1).sqrt().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bgflow import Energy, Sampler\n",
    "from torch.distributions.chi2 import Chi2\n",
    "from torch.distributions.gamma import Gamma\n",
    "\n",
    "\n",
    "class HypersphericalPrior(Energy, Sampler):\n",
    "    \n",
    "    def __init__(self, dim, concentration=1.):\n",
    "        super().__init__(dim)\n",
    "        r = np.sqrt(dim) / 2\n",
    "        rate = concentration / r\n",
    "        self._gamma = Gamma(concentration, rate)\n",
    "    \n",
    "    def _energy(self, x):\n",
    "        d2 = x.pow(2).sum(dim=-1, keepdim=True)\n",
    "        d = (d2 + 1e-7).sqrt()\n",
    "        return -self._gamma.log_prob(d)\n",
    "        \n",
    "    \n",
    "    def _sample(self, n_samples):\n",
    "        x = torch.Tensor(n_samples, self._dim).normal_()\n",
    "        d2 = x.pow(2).sum(dim=-1, keepdim=True)\n",
    "        d = (d2 + 1e-7).sqrt()\n",
    "        r = x / d\n",
    "        s = self._gamma.sample((n_samples, 1))\n",
    "#         print(s)\n",
    "        return r * s\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now set up a prior\n",
    "\n",
    "from bgflow import NormalDistribution\n",
    "\n",
    "prior = NormalDistribution(dim)\n",
    "# prior = HypersphericalPrior(dim, concentration=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a flow with RNVP coupling layers\n",
    "\n",
    "from bgflow.nn import (\n",
    "    DenseNet,\n",
    "    SequentialFlow, \n",
    "    CouplingFlow, \n",
    "    AffineFlow, \n",
    "    SplitFlow, \n",
    "    InverseFlow, \n",
    "    SwapFlow,\n",
    "    AffineTransformer\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# here we aggregate all layers of the flow\n",
    "layers = []\n",
    "\n",
    "# start with a splitting layer which splits the input tensor into two \n",
    "# flow channels with tensors of half dimensionality\n",
    "layers.append(SplitFlow(dim // 2))\n",
    "\n",
    "\n",
    "# now add coupling layers\n",
    "n_coupling_layers = 4\n",
    "for _ in range(n_coupling_layers):\n",
    "    \n",
    "    # we need to swap dimensions for the mixing\n",
    "    layers.append(SwapFlow())\n",
    "    \n",
    "    # now set up a coupling block\n",
    "    layers.append(CouplingFlow(\n",
    "        # we use a affine transformation to transform the RHS conditioned on the LHS\n",
    "        AffineTransformer(\n",
    "            # use simple dense nets for the affine shift/scale\n",
    "            shift_transformation=DenseNet([dim // 2, 64, 64, dim // 2], activation=torch.nn.ReLU()), \n",
    "            scale_transformation=DenseNet([dim // 2, 64, 64, dim // 2], activation=torch.nn.ReLU())\n",
    "        )\n",
    "    ))\n",
    "    \n",
    "# finally, we have to merge the two channels again into one tensor\n",
    "layers.append(InverseFlow(SplitFlow(dim // 2)))\n",
    "    \n",
    "# now define the flow as a sequence of all operations stored in layers\n",
    "flow = SequentialFlow(layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# having a flow and a prior, we can now define a Boltzmann Generator\n",
    "\n",
    "from bgflow import BoltzmannGenerator\n",
    "\n",
    "bg = BoltzmannGenerator(prior, flow, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial bg should not be useful\n",
    "%pdb\n",
    "plot_bg(bg, target, dim=dim)\n",
    "\n",
    "plot_weighted_energy_estimate(bg, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bgflow.utils.types import is_list_or_tuple\n",
    "\n",
    "class LossReporter:\n",
    "    \"\"\"\n",
    "        Simple reporter use for reporting losses and plotting them.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, *labels):\n",
    "        self._labels = labels\n",
    "        self._n_reported = len(labels)\n",
    "        self._raw = [[] for _ in range(self._n_reported)]\n",
    "    \n",
    "    def report(self, *losses):\n",
    "        assert len(losses) == self._n_reported\n",
    "        for i in range(self._n_reported):\n",
    "            self._raw[i].append(assert_numpy(losses[i]))\n",
    "    \n",
    "    def plot(self, n_smooth=10):\n",
    "        fig, axes = plt.subplots(self._n_reported, sharex=True)\n",
    "        if not isinstance(axes, np.ndarray):\n",
    "            axes = [axes]\n",
    "        fig.set_size_inches((8, 4 * self._n_reported), forward=True)\n",
    "        for i, (label, raw, axis) in enumerate(zip(self._labels, self._raw, axes)):\n",
    "            raw = assert_numpy(raw).reshape(-1)\n",
    "            kernel = np.ones(shape=(n_smooth,)) / n_smooth\n",
    "            smoothed = np.convolve(raw, kernel, mode=\"valid\")\n",
    "            axis.plot(smoothed)\n",
    "            axis.set_ylabel(label)\n",
    "            if i == self._n_reported - 1:\n",
    "                axis.set_xlabel(\"Iteration\")\n",
    "                \n",
    "    def recent(self, n_recent=1):\n",
    "        return np.array([raw[-n_recent:] for raw in self._raw])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial training with likelihood maximization on data set\n",
    "\n",
    "from bgflow.utils.train import IndexBatchIterator\n",
    "\n",
    "n_batch = 32\n",
    "batch_iter = IndexBatchIterator(len(data), n_batch)\n",
    "\n",
    "optim = torch.optim.Adam(bg.parameters(), lr=5e-3)\n",
    "\n",
    "n_epochs = 5\n",
    "n_report_steps = 50\n",
    "\n",
    "reporter = LossReporter(\"NLL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for it, idxs in enumerate(batch_iter):\n",
    "        batch = data[idxs]\n",
    "        \n",
    "        optim.zero_grad()\n",
    "        \n",
    "        # negative log-likelihood of the batch is equal to the energy of the BG\n",
    "        nll = bg.energy(batch).mean()\n",
    "        nll.backward()\n",
    "        \n",
    "        reporter.report(nll)\n",
    "        \n",
    "        optim.step()\n",
    "        \n",
    "        if it % n_report_steps == 0:\n",
    "            print(\"\\repoch: {0}, iter: {1}/{2}, NLL: {3:.4}\".format(\n",
    "                    epoch,\n",
    "                    it,\n",
    "                    len(batch_iter),\n",
    "                    *reporter.recent(1).ravel()\n",
    "                ), end=\"\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reporter.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bg after ML training\n",
    "\n",
    "plot_bg(bg, target, dim=dim)\n",
    "\n",
    "plot_weighted_energy_estimate(bg, target, dim=dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train with convex mixture of NLL and KL loss\n",
    "\n",
    "from bgflow.utils.train import IndexBatchIterator\n",
    "\n",
    "n_kl_samples = 128\n",
    "n_batch = 128\n",
    "batch_iter = IndexBatchIterator(len(data), n_batch)\n",
    "\n",
    "optim = torch.optim.Adam(bg.parameters(), lr=5e-3)\n",
    "\n",
    "n_epochs = 5\n",
    "n_report_steps = 50\n",
    "\n",
    "# mixing parameter\n",
    "lambdas = torch.linspace(1., 0.5, n_epochs)\n",
    "\n",
    "reporter = LossReporter(\"NLL\", \"KLL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.linspace(1., 0.5, n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for epoch, lamb in enumerate(lambdas):\n",
    "    for it, idxs in enumerate(batch_iter):\n",
    "        batch = data[idxs]\n",
    "        \n",
    "        optim.zero_grad()\n",
    "        \n",
    "        # negative log-likelihood of the batch is equal to the energy of the BG\n",
    "        nll = bg.energy(batch).mean()\n",
    "        \n",
    "        # aggregate weighted gradient\n",
    "        (lamb * nll).backward()\n",
    "        \n",
    "        # kl divergence to the target\n",
    "        kll = bg.kldiv(n_kl_samples).mean()\n",
    "\n",
    "        # aggregate weighted gradient\n",
    "        ((1. - lamb) * kll).backward()\n",
    "        \n",
    "        reporter.report(nll, kll)\n",
    "        \n",
    "        optim.step()\n",
    "        \n",
    "        if it % n_report_steps == 0:\n",
    "            print(\"\\repoch: {0}, iter: {1}/{2}, lambda: {3}, NLL: {4:.4}, KLL: {5:.4}\".format(\n",
    "                    epoch,\n",
    "                    it,\n",
    "                    len(batch_iter),\n",
    "                    lamb,\n",
    "                    *reporter.recent(1).ravel()\n",
    "                ), end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reporter.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bg after ML + KL training\n",
    "\n",
    "plot_bg(bg, target, dim=dim)\n",
    "\n",
    "plot_weighted_energy_estimate(bg, target, dim=dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
